---
title: "USGS Stream Data Project"
author: "Shale"
date: "10/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dataRetrieval)
library(metajam)
library(here)
```

## Ventura River data for this week

```{r}
# readNWISdv() is for daily values, readNWISuv() is for smaller time intervals (15 min)

SB_creeks = readNWISuv(siteNumbers = c(11118500, 11113500), parameterCd = c("00060", "00065"), startDate = "2021-10-03", endDate = "2021-10-05", tz = "America/Los_Angeles") %>% 
  renameNWISColumns() 

# It seems that the simplest way to query multiple sites is to just create a vector of site ids to use as input to the `readNWISdv()` function.

ggplot(SB_creeks, aes(x= dateTime, y= Flow_Inst)) +
  geom_point(aes(color = site_no, shape = site_no))
#  scale_fill_discrete(name = "Creek Site", labels = c("Santa Paula Creek", "Ventura River"))

# The Ventura River (site 11118500) is probably dammed, because during the time of the storm (and expected flow surge) the flow plateaued at 1.08 cubic feet per second. Looking at longitudinal data for the same site shows this as a recurring ceiling, which hints at a restrictive feature such as a dam.

# Santa Paula Creek (site 11113500), on the other hand, has a distinct apex on Tuesday morning following the storm of Monday night. This is obvious visually on the graph, but can be pinpointed exactly with the code below.

V_max = SB_creeks %>% 
  filter(site_no == 11113500) %>% 
  filter(Flow_Inst == max(Flow_Inst))
  
print(V_max$dateTime)  

# Shows that discharge of Santa Paula Creek at the monitoring station peaked between 3:30AM and 4:15AM of October 5th.
```

```{r, echo=FALSE}
bbox_sites = whatNWISsites(bBox=c(-83.0,36.5,-81.0,38.5), 
                      parameterCd=c("00010","00060"),
                      hasDataTypeCd="dv")
```

## metajam

```{r}
alaska_data_obj = download_d1_data(data_url = "https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3A7fc6f6db-c5ea-426a-a743-1f2edafb43b8", path = here())

# Works on Taylor, but not on my laptop. Error message:
# Error in h(simpleError(msg, call)) : error in evaluating the argument 'x' in selecting a method for function 'query': SSL certificate problem: certificate has expired

alaska_data = read_d1_files(folder_path = alaska_data_obj)

alaska_df = alaska_data$data
```

## Manual attempt bc of SSL error

Error resolved on Taylor, but not on my personal computer - metajam is working for me now on Taylor, but I am still getting an SSL error when I try to run `alaska_data_obj =` on my laptop. Everything done below with `alaska_data_m` (manual download) could be repeated identically with the same data using `metajam`, which is now stored in `alaska_df` above.

```{r}
alaska_data_m = read_csv(here("manual/household_language.csv"))
```

```{r}
english_only = alaska_data_m %>% 
  group_by(Year) %>% 
  summarise(pct_English_only = 100 * (sum(speak_only_english) / sum(total))) %>% 
  filter(Year >= 2009)

ggplot(english_only, aes(x= Year, y= pct_English_only)) +
  geom_line() +
  geom_point(color = "red") +
  labs(title = "Percent of Alaskans speaking only English by year, 2009-2015")
```

And in French

```{r}
# "French" isn't defined in the question as it relates to the possible columns in the df, so I chose to use the `french_incl_patois_cajun` variable.
french_lang = alaska_data_m %>% 
  group_by(Year) %>% 
  summarise(pct_french = 100 * (sum(french_incl_patois_cajun) / sum(total))) %>% 
  filter(Year >= 2009)

ggplot(french_lang, aes(x= Year, y= pct_french)) +
  geom_line() +
  geom_point(color = "red") +
  labs(title = "Percent of Alaskans speaking French 
(including Patois/Cajun) by year, 2009-2015")
```

